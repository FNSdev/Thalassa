apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: count-words
  namespace: spark-applications
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "thalassa/spark:0.0.1"
  imagePullPolicy: IfNotPresent
  mainApplicationFile: local:///opt/spark/work-dir/spark_jobs/count_words.py
  sparkVersion: "3.4.0"
  deps:
    # for some reason, specifying dependencies as "packages" doesn't work properly
    # as a workaround, I decided to copy jar files into the docker image
    jars:
      - local:///opt/spark/work-dir/jars/bson-4.8.2.jar
      - local:///opt/spark/work-dir/jars/bson-record-codec-4.8.2.jar
      - local:///opt/spark/work-dir/jars/mongo-spark-connector_2.12-10.1.1.jar
      - local:///opt/spark/work-dir/jars/mongodb-driver-core-4.8.2.jar
      - local:///opt/spark/work-dir/jars/mongodb-driver-sync-4.8.2.jar
  sparkConf:
    spark.mongodb.read.connection.uri: mongodb://thalassa:thalassa@100.120.8.200/thalassa
    spark.mongodb.write.connection.uri: mongodb://thalassa:thalassa@100.120.8.200/thalassa
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  timeToLiveSeconds: 3600
  driver:
    labels:
      version: 3.1.1
    serviceAccount: spark
  executor:
    cores: 1
    instances: 1
    labels:
      version: 3.1.1
